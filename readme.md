![Python](https://img.shields.io/badge/python-3.x-blue)
![License](https://img.shields.io/github/license/flavioro/job_scraper_ia)

# Job Scraper IA (Python + Ollama + SQLite)

Pipeline local em Python para coletar vagas via URLs diretas, realizar scraping robusto com fallback, extrair campos estruturados usando LLM local (Ollama), deduplicar e persistir histÃ³rico em SQLite, com export automÃ¡tico para CSV e Excel (XLSX).

> Projeto focado em automaÃ§Ã£o, backend e dados, com execuÃ§Ã£o 100% local.

---

## ğŸ¯ Objetivo

Automatizar a coleta e organizaÃ§Ã£o de vagas a partir de links diretos, gerando uma base histÃ³rica consultÃ¡vel e arquivos finais prontos para uso (CSV/XLSX).

---

## âœ… Features

- Coleta de vagas por **lista de URLs**
- Scraping robusto com **fallback**
- ExtraÃ§Ã£o estruturada com **IA local (Ollama)**
- ReduÃ§Ã£o e limpeza de texto para otimizar custo/tempo de LLM
- DeduplicaÃ§Ã£o e persistÃªncia de histÃ³rico em **SQLite**
- Export automÃ¡tico para:
  - CSV
  - Excel (.xlsx)
- Logs detalhados para auditoria e debug
- Arquitetura modular e pronta para expansÃ£o

---

## ğŸ§  Tecnologias e CompetÃªncias

**Stack:**
- Python
- Web Scraping
- SQLite
- Data Processing
- AutomaÃ§Ã£o
- ETL (conceito)
- LLM local (Ollama)
- APIs
- Export CSV/XLSX

---

## ğŸ–¥ï¸ Demo

> As imagens abaixo mostram o pipeline em execuÃ§Ã£o e o output final gerado automaticamente.

### ExecuÃ§Ã£o (logs do pipeline)
![ExecuÃ§Ã£o do pipeline](img/spyder_console_flow.png)

### Output gerado (Excel)
![Planilha gerada](img/excel_output.png)

---

## ğŸ—ï¸ Arquitetura (VisÃ£o Geral)

O pipeline Ã© organizado em etapas independentes, com foco em confiabilidade e reaproveitamento:

1. Entrada: lista de URLs de vagas  
2. Scraping + fallback (caso layout falhe)  
3. ReduÃ§Ã£o de texto (limpeza e otimizaÃ§Ã£o)  
4. ExtraÃ§Ã£o estruturada com IA local (Ollama)  
5. ValidaÃ§Ã£o de chaves mÃ­nimas  
6. DeduplicaÃ§Ã£o (hash) e persistÃªncia em SQLite  
7. Export automÃ¡tico para CSV e Excel  

---

## ğŸ“¦ Estrutura do Projeto

```txt
job_scraper_ia/
â”œâ”€â”€ main.py
â”œâ”€â”€ config.json
â”œâ”€â”€ db.py
â”œâ”€â”€ export_db.py
â”œâ”€â”€ output/
â”œâ”€â”€ README.md
â””â”€â”€ ...
```

---

## â–¶ï¸ Como executar (Windows)

### 1) Clonar o projeto
```bash
git clone https://github.com/flavioro/job_scraper_ia.git
cd job_scraper_ia
```

### 2) Criar ambiente virtual
```bash
python -m venv venv
venv\Scripts\activate
```

### 3) Instalar dependÃªncias
```bash
pip install -r requirements.txt
```

### 4) Rodar o Ollama localmente
- Instale o Ollama: https://ollama.com/
- Baixe um modelo (exemplo):
```bash
ollama pull qwen2.5:7b
```

### 5) Executar o pipeline
```bash
python main.py
```

---

## ğŸ“¤ SaÃ­das geradas

O projeto gera automaticamente arquivos no diretÃ³rio `output/`, por exemplo:

- `output/vagas_output_all.csv`
- `output/vagas_output_all.xlsx`
- `output/vagas_output_jr_pleno_ativas.csv`
- `output/vagas_output_jr_pleno_ativas.xlsx`

---

## ğŸ” Campos extraÃ­dos (exemplo)

O pipeline tenta estruturar campos como:

- Empresa
- Cargo
- Localidade / Remoto
- Tipo de trabalho (remoto / hÃ­brido / presencial)
- Senioridade
- SalÃ¡rio (quando disponÃ­vel)
- Link de candidatura
- Data da publicaÃ§Ã£o
- Score (0 a 100)
- Motivo curto (feedback do match)

---

## ğŸ“Œ ObservaÃ§Ãµes

- O projeto roda **100% local**, sem depender de API paga.
- A qualidade da extraÃ§Ã£o pode variar conforme o layout e o texto da vaga.
- A arquitetura Ã© preparada para adicionar novos sites/fontes facilmente.

---

## ğŸ§© PrÃ³ximas melhorias (ideias)

- [ ] Dashboard (Streamlit) para visualizar e filtrar vagas
- [ ] IntegraÃ§Ã£o com mais fontes (Gupy, Workday, Lever, Greenhouse etc)
- [ ] Cache inteligente por domÃ­nio
- [ ] Scheduler (execuÃ§Ã£o automÃ¡tica diÃ¡ria)
- [ ] Export com filtros personalizados

---

## ğŸ‘¤ Autor

**Flavio Rodrigues**  
LinkedIn: https://www.linkedin.com/in/flaviorobertorodrigues/  
GitHub: https://github.com/flavioro
